{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.diffusion.ddpm import DDPM\n",
    "from src.diffusion.unet import UNet\n",
    "from src.data.mnist import get_mnist_loader_and_transform\n",
    "from src.data.cifar10 import get_cifar10_loader_and_transform\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from src.diffusion.train import train\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.backends\n",
    "import torch.backends.mps\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = 1000\n",
    "os.makedirs(\"projects/diffusion/stable-diffusion-from-scratch/loss\", exist_ok=True)\n",
    "dataset = \"mnist\" # can be \"cifar10\" or \"mnist\"\n",
    "\n",
    "PATH_TO_READY_MODEL = None # input path for ready model\n",
    "\n",
    "PATH_TO_SAVE_MODEL = \"model.pth\"\n",
    "EPOCHS = 50 # for cifar10 it should be more than 1000, but for mnist 20-100 should be okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"mnist\":\n",
    "    data = get_mnist_loader_and_transform()\n",
    "elif dataset == \"cifar10\":\n",
    "    data = get_cifar10_loader_and_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm = DDPM(\n",
    "    T = T,\n",
    "    eps_model=UNet(\n",
    "        in_channels=data.in_channels,\n",
    "        out_channels=data.out_channels,\n",
    "        T=T+1,\n",
    "        steps=data.recommended_steps,\n",
    "        attn_step_indexes=data.recommended_attn_step_indexes\n",
    "    ),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or load ready model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss for epoch 0: 0.1201:  25%|██▌       | 118/469 [00:17<00:52,  6.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     ddpm\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(PATH_TO_READY_MODEL, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     training_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddpm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loader\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     path \u001b[38;5;241m=\u001b[39m PATH_TO_SAVE_MODEL \u001b[38;5;28;01mif\u001b[39;00m PATH_TO_SAVE_MODEL \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(ddpm\u001b[38;5;241m.\u001b[39mstate_dict(), path)\n",
      "File \u001b[0;32m~/projects/diffusion/stable-diffusion-from-scratch/src/diffusion/train.py:30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs, device, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     28\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 30\u001b[0m     training_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss for epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(index\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if PATH_TO_READY_MODEL is not None:\n",
    "    ddpm.load_state_dict(torch.load(PATH_TO_READY_MODEL, map_location=device))\n",
    "else:\n",
    "    training_losses, val_losses = train(\n",
    "        model=ddpm,\n",
    "        optimizer=torch.optim.Adam(params=ddpm.parameters(), lr=2e-4),\n",
    "        epochs=EPOCHS,\n",
    "        device=device,\n",
    "        train_dataloader=data.train_loader,\n",
    "        val_dataloader=data.val_loader\n",
    "    )\n",
    "\n",
    "    path = PATH_TO_SAVE_MODEL if PATH_TO_SAVE_MODEL is not None else \"model.pth\"\n",
    "\n",
    "    torch.save(ddpm.state_dict(), path)\n",
    "\n",
    "\n",
    "    \n",
    "    # 生成时间戳，避免文件名冲突\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 方案1：保存为图像\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\", linewidth=2)\n",
    "    plt.plot(val_losses, label=\"Validation Loss\", linewidth=2)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Training Loss Curves (Final: Train={train_losses[-1]:.6f}, Val={val_losses[-1]:.6f})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    # 确保loss文件夹存在\n",
    "    os.makedirs(loss, exist_ok=True)\n",
    "    # 保存图像\n",
    "    img_path = os.path.join(loss, f\"loss_curves_{timestamp}.png\")\n",
    "    plt.savefig(img_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Loss曲线图像已保存到: {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "x_t = ddpm.sample(n_samples=n_samples, size=data.train_dataset[0][0].shape)\n",
    "\n",
    "result = []\n",
    "for i in range(x_t.shape[0]):\n",
    "    result.append(data.transform_to_pil(x_t[i]))\n",
    "\n",
    "grid = make_grid(x_t, nrow=10)\n",
    "save_image(grid, f\"sample.png\")\n",
    "\n",
    "cols = 5\n",
    "rows = (n_samples // cols) + (0 if n_samples % cols == 0 else 1)\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
    "for i in range(len(result)):\n",
    "    row = i // cols\n",
    "    axs[row, i % cols].imshow(result[i], cmap='gray')\n",
    "    \n",
    "\n",
    "\n",
    "os.system(\"/usr/bin/shutdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
